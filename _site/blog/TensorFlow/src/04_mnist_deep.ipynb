{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../data/mnist_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAccuracy(H, Y): # 예측치와 정확도 함수\n",
    "    prediction = tf.equal(tf.argmax(H, axis=1), tf.argmax(Y, axis=1))\n",
    "    accuracy   = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "    return prediction, accuracy\n",
    "\n",
    "def getCost(mylogits, mylabel): # 비용 함수를 구해주는 함수\n",
    "    diff = tf.nn.softmax_cross_entropy_with_logits(logits= mylogits, labels = mylabel)\n",
    "    cost = tf.reduce_mean(diff)\n",
    "    return cost\n",
    "\n",
    "def getOptimizer(learn_rate): # 옵티마이저 구하기\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learn_rate)\n",
    "    train     = optimizer.minimize(cost)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-f1d66b7bcd17>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "nb_classes = 10\n",
    "img_row    = 28\n",
    "img_column = 28\n",
    "mnistimg   = img_row * img_column\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, mnistimg])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, nb_classes])\n",
    "\n",
    "# W1 = tf.Variable(tf.random_normal(shape=[mnistimg, 256]))\n",
    "W1 = tf.get_variable('W1', shape=[mnistimg,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal(shape=[512]))\n",
    "H1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal(shape=[256, 256]))\n",
    "W2 = tf.get_variable('W2', shape=[512,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal(shape=[512]))\n",
    "H2 = tf.nn.relu(tf.matmul(H1, W2) + b2)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal(shape=[256, 256]))\n",
    "W3 = tf.get_variable('W3', shape=[512,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal(shape=[512]))\n",
    "H3 = tf.nn.relu(tf.matmul(H2, W3) + b3)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal(shape=[256, 256]))\n",
    "W4 = tf.get_variable('W4', shape=[512,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal(shape=[512]))\n",
    "H4 = tf.nn.relu(tf.matmul(H3, W4) + b4)\n",
    "\n",
    "# W3 = tf.Variable(tf.random_normal(shape=[256, nb_classes]))\n",
    "W5 = tf.get_variable('W5', shape=[512,nb_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal(shape=[nb_classes]))\n",
    "\n",
    "logits = tf.matmul(H4, W5) + b5\n",
    "H = tf.nn.softmax(logits)\n",
    "\n",
    "cost = getCost(logits, Y)\n",
    "\n",
    "train = getOptimizer( learn_rate )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.293363996\n",
      "0.102459753\n",
      "0.068836756\n",
      "0.051891984\n",
      "0.040307011\n",
      "0.036784132\n",
      "0.028907757\n",
      "0.026712676\n",
      "0.021036193\n",
      "0.022467411\n",
      "0.017309584\n",
      "0.018346841\n",
      "0.015330495\n",
      "0.018156131\n",
      "0.016689723\n",
      "training finished\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train._num_examples / batch_size)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    total_cost = 0 #비용 전체의 합\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        feed_data = {X:batch_xs, Y:batch_ys}\n",
    "        _cost, _train = sess.run([cost, train], feed_dict=feed_data)\n",
    "        \n",
    "        total_cost += _cost\n",
    "        \n",
    "    # avg_cost : 평균비용\n",
    "    avg_cost = total_cost / total_batch\n",
    "    \n",
    "    print('{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('training finished')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 정확도:[0.9781]\n",
      "\n",
      "라벨(Label) : [1]\n",
      "\n",
      "예측(Prediction) : [7 2 1 ... 4 5 6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 테스트와 정확도 체크하기\n",
    "prediction, accuracy = predictAccuracy(H, Y)\n",
    "\n",
    "print('\\n 정확도:', end='')\n",
    "\n",
    "feed_data = {X:mnist.test.images, Y:mnist.test.labels}\n",
    "\n",
    "print(sess.run([accuracy], feed_dict= feed_data))\n",
    "\n",
    "# 임의의 그림 1개를 구하고, 예측하기\n",
    "randitem  = random.randint(0, mnist.test.num_examples -1)\n",
    "print('\\n라벨(Label) :', end=' ')\n",
    "print(sess.run(tf.argmax(mnist.test.labels[randitem:randitem+1], axis=1)))\n",
    "\n",
    "print('\\n예측(Prediction) :', end=' ')\n",
    "feed_data={X:mnist.test.images[randitem:randitem+1]}\n",
    "print(sess.run(tf.argmax(H, axis=1), feed_dict = feed_data))\n",
    "\n",
    "plt.imshow(mnist.test.images[randitem:randitem+1].reshape(img_row, img_column), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
