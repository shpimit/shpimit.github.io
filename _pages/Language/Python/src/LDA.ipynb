{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# DTM\n",
    "documents = defaultdict(lambda: defaultdict(int))\n",
    "vocabulary = list()\n",
    "\n",
    "for i, d in enumerate(collection): # i:문서제목, d: i번째  문서 내 단어목록\n",
    "    for term in d:\n",
    "        documents[i][term.lower()] += 1\n",
    "        vocabulary.append(term.lower())\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.1\n",
    "b = 0.1\n",
    "\n",
    "K = 3 # 토픽 수\n",
    "\n",
    "M = len(documents)\n",
    "V = len(vocabulary)\n",
    "\n",
    "# 특정 토픽에 몇개의 단어가 있는지 → 분모\n",
    "topicTermCount = defaultdict(int)\n",
    "\n",
    "# 특정 문서의 단어에 상관없이 토픽 할당 횟수\n",
    "docTopicDistribution = defaultdict(lambda:defaultdict(int))\n",
    "\n",
    "# 문서에 상관없이 특정 단어의 토픽 할당 횟수\n",
    "topicTermDistribution = defaultdict(lambda:defaultdict(int))\n",
    "# [topic][Vocabulary 0:몇번, ..., n]\n",
    "\n",
    "# Z_ml = m번째 문서 1번째 단어의 Topic\n",
    "# M개의 문서만큼 → N개의 단어 → Topic\n",
    "termTopicAssignmentMatrix = defaultdict(lambda:defaultdict(int))\n",
    "# Z[document][term] = Topic\n",
    "# n(i, (j, r)) = i번째 토픽의 횟수, j번째 문서의 r번째 단어\n",
    "\n",
    "# m번째 문서의 l번째의 단어의 K(topic)을 찾는것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize, Randomly\n",
    "from random import randrange, seed, random\n",
    "\n",
    "seed(0)\n",
    "\n",
    "\n",
    "# collection이라는 것은 원본\n",
    "for i, termList in enumerate(collection):\n",
    "    for j, term in enumerate(termList):\n",
    "        token = term.lower()\n",
    "        topic = randrange(K)\n",
    "        \n",
    "        topicTermCount[topic] += 1\n",
    "        docTopicDistribution[i][topic] += 1\n",
    "        topicTermDistribution[topic][term] += 1\n",
    "        \n",
    "        termTopicAssignmentMatrix[i][j] = topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 45, 0: 40, 2: 48})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicTermCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {0: defaultdict(int, {0: 1, 1: 1, 2: 0, 3: 1, 4: 2, 5: 1, 6: 1}),\n",
       "             1: defaultdict(int, {0: 1, 1: 1, 2: 1, 3: 2, 4: 0}),\n",
       "             2: defaultdict(int, {0: 2, 1: 0, 2: 1, 3: 0, 4: 0, 5: 2}),\n",
       "             3: defaultdict(int, {0: 1, 1: 2, 2: 2, 3: 2, 4: 0}),\n",
       "             4: defaultdict(int, {0: 1, 1: 0, 2: 2, 3: 0}),\n",
       "             5: defaultdict(int, {0: 2, 1: 1, 2: 1, 3: 2, 4: 0, 5: 1}),\n",
       "             6: defaultdict(int, {0: 1, 1: 1, 2: 2, 3: 2}),\n",
       "             7: defaultdict(int, {0: 0, 1: 2, 2: 1, 3: 1}),\n",
       "             8: defaultdict(int, {0: 2, 1: 1, 2: 0, 3: 2}),\n",
       "             9: defaultdict(int, {0: 0, 1: 0, 2: 2, 3: 1}),\n",
       "             10: defaultdict(int, {0: 2, 1: 2, 2: 2}),\n",
       "             11: defaultdict(int, {0: 0, 1: 2, 2: 1, 3: 1}),\n",
       "             12: defaultdict(int, {0: 0, 1: 2, 2: 1}),\n",
       "             13: defaultdict(int, {0: 2, 1: 0, 2: 0, 3: 2, 4: 0}),\n",
       "             14: defaultdict(int, {0: 0, 1: 0, 2: 2})})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termTopicAssignmentMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {0: defaultdict(int, {1: 9, 0: 2, 2: 2}),\n",
       "             1: defaultdict(int, {1: 6, 2: 2, 0: 2}),\n",
       "             2: defaultdict(int, {2: 4, 0: 6, 1: 2}),\n",
       "             3: defaultdict(int, {1: 2, 2: 6, 0: 2}),\n",
       "             4: defaultdict(int, {1: 2, 0: 4, 2: 2}),\n",
       "             5: defaultdict(int, {2: 4, 1: 6, 0: 2}),\n",
       "             6: defaultdict(int, {1: 4, 2: 4}),\n",
       "             7: defaultdict(int, {0: 2, 2: 2, 1: 4}),\n",
       "             8: defaultdict(int, {2: 4, 1: 2, 0: 2}),\n",
       "             9: defaultdict(int, {0: 4, 2: 2, 1: 2}),\n",
       "             10: defaultdict(int, {2: 6}),\n",
       "             11: defaultdict(int, {0: 2, 2: 2, 1: 4}),\n",
       "             12: defaultdict(int, {0: 2, 2: 2, 1: 2}),\n",
       "             13: defaultdict(int, {2: 4, 0: 6}),\n",
       "             14: defaultdict(int, {0: 4, 2: 2})})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docTopicDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {1: defaultdict(int,\n",
       "                         {'Hadoop': 1,\n",
       "                          'Big Data': 4,\n",
       "                          'Java': 4,\n",
       "                          'Storm': 2,\n",
       "                          'Cassandra': 4,\n",
       "                          'NoSQL': 2,\n",
       "                          'MongoDB': 2,\n",
       "                          'scipy': 2,\n",
       "                          'R': 4,\n",
       "                          'machine learning': 2,\n",
       "                          'programming languages': 2,\n",
       "                          'statistics': 2,\n",
       "                          'probability': 4,\n",
       "                          'Mahout': 2,\n",
       "                          'neural networks': 2,\n",
       "                          'deep learning': 2,\n",
       "                          'artificial intelligence': 2,\n",
       "                          'Python': 2}),\n",
       "             0: defaultdict(int,\n",
       "                         {'HBase': 4,\n",
       "                          'Postgres': 4,\n",
       "                          'scikit-learn': 2,\n",
       "                          'numpy': 2,\n",
       "                          'statsmodels': 2,\n",
       "                          'probability': 2,\n",
       "                          'regression': 4,\n",
       "                          'libsvm': 4,\n",
       "                          'Haskell': 2,\n",
       "                          'machine learning': 2,\n",
       "                          'Big Data': 2,\n",
       "                          'Hadoop': 2,\n",
       "                          'Java': 2,\n",
       "                          'C++': 2,\n",
       "                          'pandas': 2,\n",
       "                          'MongoDB': 2}),\n",
       "             2: defaultdict(int,\n",
       "                         {'Spark': 2,\n",
       "                          'HBase': 2,\n",
       "                          'Python': 6,\n",
       "                          'pandas': 2,\n",
       "                          'statistics': 4,\n",
       "                          'regression': 2,\n",
       "                          'decision trees': 2,\n",
       "                          'C++': 2,\n",
       "                          'mathematics': 2,\n",
       "                          'theory': 2,\n",
       "                          'scikit-learn': 2,\n",
       "                          'neural networks': 2,\n",
       "                          'artificial intelligence': 2,\n",
       "                          'MapReduce': 2,\n",
       "                          'R': 4,\n",
       "                          'statsmodels': 2,\n",
       "                          'deep learning': 2,\n",
       "                          'databases': 2,\n",
       "                          'MySQL': 2,\n",
       "                          'support vector machines': 2,\n",
       "                          'Hadoop': 0})})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicTermDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihoodAlpha(i, k):    # 문서, 토픽\n",
    "    return docTopicDistribution[i][k] + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihoodBeta(k, term):    # 토픽, term\n",
    "    return (topicTermDistribution[k][term] + b) / (topicTermCount[k] + (b * V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapsedGibbsSampling(i, term):\n",
    "    sampling = list()\n",
    "    for k in range(K):\n",
    "        # k번째 토픽에 대한 확률\n",
    "        sampling.append(likelihoodAlpha(i, k) * likelihoodBeta(k, term))\n",
    "        \n",
    "    threshold = sum(sampling) * random()    # 0~1 사이의 값 (sample 들 중에서 위치 선택) => 적당한 k번째를 고르기 위한 샘플링\n",
    "    \n",
    "    for topicNo, topicProbability in enumerate(sampling):\n",
    "        threshold -= topicProbability\n",
    "        \n",
    "        if threshold <= 0.0:\n",
    "            return topicNo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterationNumber = 1000\n",
    "\n",
    "for _ in range(iterationNumber):\n",
    "    for i, termList in enumerate(collection):\n",
    "        for j, term in enumerate(termList):\n",
    "            topic = termTopicAssignmentMatrix[i][j]\n",
    "\n",
    "            topicTermCount[topic] -= 1\n",
    "            docTopicDistribution[i][topic] -= 1\n",
    "            topicTermDistribution[topic][term] -= 1\n",
    "\n",
    "            topic = collapsedGibbsSampling(i, term)\n",
    "\n",
    "            topicTermCount[topic] += 1\n",
    "            docTopicDistribution[i][topic] += 1\n",
    "            topicTermDistribution[topic][term] += 1\n",
    "\n",
    "            termTopicAssignmentMatrix[i][j] = topic    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {0: defaultdict(int, {1: 8, 0: 3, 2: 2}),\n",
       "             1: defaultdict(int, {1: 5, 2: 1, 0: 4}),\n",
       "             2: defaultdict(int, {2: 2, 0: 8, 1: 2}),\n",
       "             3: defaultdict(int, {1: 2, 2: 5, 0: 3}),\n",
       "             4: defaultdict(int, {1: 1, 0: 5, 2: 2}),\n",
       "             5: defaultdict(int, {2: 3, 1: 6, 0: 3}),\n",
       "             6: defaultdict(int, {1: 2, 2: 6, 0: 0}),\n",
       "             7: defaultdict(int, {0: 2, 2: 1, 1: 5}),\n",
       "             8: defaultdict(int, {2: 5, 1: 2, 0: 1}),\n",
       "             9: defaultdict(int, {0: 4, 2: 1, 1: 3}),\n",
       "             10: defaultdict(int, {2: 6, 0: 0, 1: 0}),\n",
       "             11: defaultdict(int, {0: 1, 2: 2, 1: 5}),\n",
       "             12: defaultdict(int, {0: 1, 2: 4, 1: 1}),\n",
       "             13: defaultdict(int, {2: 4, 0: 6, 1: 0}),\n",
       "             14: defaultdict(int, {0: 4, 2: 2, 1: 0})})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docTopicDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {1: defaultdict(int,\n",
       "                         {'Hadoop': 0,\n",
       "                          'Big Data': 5,\n",
       "                          'Java': 5,\n",
       "                          'Storm': 2,\n",
       "                          'Cassandra': 4,\n",
       "                          'NoSQL': 2,\n",
       "                          'MongoDB': 1,\n",
       "                          'scipy': 2,\n",
       "                          'R': 3,\n",
       "                          'machine learning': 2,\n",
       "                          'programming languages': 2,\n",
       "                          'statistics': 1,\n",
       "                          'probability': 4,\n",
       "                          'Mahout': 2,\n",
       "                          'neural networks': 2,\n",
       "                          'deep learning': 2,\n",
       "                          'artificial intelligence': 2,\n",
       "                          'Python': 1,\n",
       "                          'HBase': 0,\n",
       "                          'Spark': 0,\n",
       "                          'Postgres': 0,\n",
       "                          'scikit-learn': 0,\n",
       "                          'numpy': 0,\n",
       "                          'statsmodels': 0,\n",
       "                          'pandas': 0,\n",
       "                          'regression': 0,\n",
       "                          'decision trees': 0,\n",
       "                          'libsvm': 0,\n",
       "                          'C++': 0,\n",
       "                          'Haskell': 0,\n",
       "                          'mathematics': 0,\n",
       "                          'theory': 0,\n",
       "                          'MapReduce': 0,\n",
       "                          'databases': 0,\n",
       "                          'MySQL': 0,\n",
       "                          'support vector machines': 0}),\n",
       "             0: defaultdict(int,\n",
       "                         {'HBase': 4,\n",
       "                          'Postgres': 4,\n",
       "                          'scikit-learn': 3,\n",
       "                          'numpy': 2,\n",
       "                          'statsmodels': 2,\n",
       "                          'probability': 1,\n",
       "                          'regression': 5,\n",
       "                          'libsvm': 4,\n",
       "                          'Haskell': 2,\n",
       "                          'machine learning': 2,\n",
       "                          'Big Data': 1,\n",
       "                          'Hadoop': 3,\n",
       "                          'Java': 1,\n",
       "                          'C++': 2,\n",
       "                          'pandas': 2,\n",
       "                          'MongoDB': 3,\n",
       "                          'Spark': 1,\n",
       "                          'Storm': 0,\n",
       "                          'Cassandra': 0,\n",
       "                          'NoSQL': 0,\n",
       "                          'Python': 2,\n",
       "                          'scipy': 0,\n",
       "                          'R': 0,\n",
       "                          'statistics': 0,\n",
       "                          'decision trees': 0,\n",
       "                          'programming languages': 0,\n",
       "                          'mathematics': 0,\n",
       "                          'theory': 0,\n",
       "                          'Mahout': 0,\n",
       "                          'neural networks': 0,\n",
       "                          'deep learning': 0,\n",
       "                          'artificial intelligence': 0,\n",
       "                          'MapReduce': 1,\n",
       "                          'databases': 0,\n",
       "                          'MySQL': 0,\n",
       "                          'support vector machines': 0}),\n",
       "             2: defaultdict(int,\n",
       "                         {'Spark': 1,\n",
       "                          'HBase': 2,\n",
       "                          'Python': 5,\n",
       "                          'pandas': 2,\n",
       "                          'statistics': 5,\n",
       "                          'regression': 1,\n",
       "                          'decision trees': 2,\n",
       "                          'C++': 2,\n",
       "                          'mathematics': 2,\n",
       "                          'theory': 2,\n",
       "                          'scikit-learn': 1,\n",
       "                          'neural networks': 2,\n",
       "                          'artificial intelligence': 2,\n",
       "                          'MapReduce': 1,\n",
       "                          'R': 5,\n",
       "                          'statsmodels': 2,\n",
       "                          'deep learning': 2,\n",
       "                          'databases': 2,\n",
       "                          'MySQL': 2,\n",
       "                          'support vector machines': 2,\n",
       "                          'Hadoop': 0,\n",
       "                          'Big Data': 0,\n",
       "                          'Java': 0,\n",
       "                          'Storm': 0,\n",
       "                          'Cassandra': 0,\n",
       "                          'NoSQL': 0,\n",
       "                          'MongoDB': 0,\n",
       "                          'Postgres': 0,\n",
       "                          'scipy': 0,\n",
       "                          'numpy': 0,\n",
       "                          'probability': 1,\n",
       "                          'machine learning': 0,\n",
       "                          'libsvm': 0,\n",
       "                          'Haskell': 0,\n",
       "                          'programming languages': 0,\n",
       "                          'Mahout': 0})})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicTermDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
