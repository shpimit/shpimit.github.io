---
layout: page
title: Computer Vision IN 한국IT비즈니스진흥협회
summary: Computer Vision is space to learn Computer Vision with Keras, Pytorch.
categories: Keras
tags: Keras
featured-img: ai
comments: 한국IT비즈니스진흥협회 ICT이노베이션 인공지능센터 언어지능프로젝트
---

# Introducing Computer Vision !!

#####  Computer Vision is space to learn Computer Vision with Keras, Pytorch.

---

## Table of Contents

|No|Title|Remarks|
|-:|:--:|:-|
|1|[교육과정](#Curriculum)|수업게시판|
|2|[Keras](#Keras)|Keras Computer Vision 소스|

---

## Curriculum

* [수업사이트](https://lms.koipa.or.kr)

### Table of Curriculum

|No|구분|Title|Day|Remarks|
|-:|:-:|:--:|:-:|:--|
|1|정규|[컴퓨터 비전과 딥러닝을 이용한 영상처리 개론](/_pages/Language/Python/data/Blockchain.pptx)|Sep 2 2019|`불참`|
|2|정규|[Single Neuron Training](/_pages/Language/Python/data/HTTP.pptx)|Sep 3 2019|`불참`|
|3|정규|[Numpy 기초 및 CNN 기초](/_pages/Language/Python/data/오픈소스개발방식_QA통합.pdf)|Sep 4 2019|`참석`|
|4|정규|CNN 기초 및 Python Open CV 실습|Sep 5 2019|`참석`|
|5|특강|[딥 러닝 활용 사례 (금융)](/_pages/Language/Python/data/DOM.pdf)|Sep 6 2019|`참석`|
|6|특강|OpenCV - 0(`설치및 기초 강의`)|Sep 9 2019|`참석`|
|7|정규|이진분류, 값 예측 딥 러닝 네트워크 설계|Sep 10 2019|`참석`|
|8|정규|Python 기초 및 Scipy 기초 실습|Sep 16 2019|`참석`|
|9|정규|[Flicker api를 이용한 데이터 수집 및 VGG 네트워크 활용](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/Language/Python/src/KOIPA-NLP/NaverNews.ipynb)|Sep 17 2019|`참석`|
|10|정규|Data Augmentation 및 CNN 모델 훈련|Sep 18 2019|`불참`|
|11|정규|자기 부호화기 Autoencoder 활용하기|Sep 19 2019|`참석`|
|12|정규|뉴럴 네트워크 훈련 기법|Sep 20 2019|`참석`|
|13|정규|CNN REVIEW|Sep 23 2019|`참석`|
|14|특강|OPENCV-1|Sep 24 2019|`불참`|
|15|정규|Kaggle Intel Image clasification|Sep 25 2019|`불참`|
|16|특강|OPENCV-2|Sep 26 2019|`참석`|
|17|정규|영상 분할(segmentation) 2|Sep 27 2019|`참석`|
|18|정규|영상 분할segmentation 고급 1|Sep 30 2019|`참석`|
|19|정규|영상 분할segmentation 고급 2|Oct 1 2019|`불참`|
|20|정규|영상 분할 segmentation Review|Oct 2 2019|`참석`|
|21|정규|Kaggle을 이용한 영상 분할 Kernel 분석1|Oct 7 2019|`참석`|
|22|특강|OpenCV 3|Oct 8 2019|`불참`|
|23|정규|GAN 기초 1|Oct 10 2019|`불참`|
|24|정규|GAN 기초 2|Oct 11 2019|`참석`|
|25|정규|Style Transfer|Oct 14 2019|`참석`|
|26|정규|OpenCV 4|Oct 15 2019|`불참`|
|26|정규|DCGAN|Oct 16 2019|`참석`|
|27|정규|Cycle GAN|Oct 17 2019|`참석`|
|28|정규|OpenCV 5|Oct 18 2019|`불참`|
|29|정규|WGAN, WGAN-GP|Oct 21 2019|`참석`|
|30|정규|GAN Review 1|Oct 22 2019|`참석`|
|31|정규|Object segmentation review #1|Oct 23 2019|`불참`|
|32|정규|Object segmentation review #2|Oct 24 2019|`참석`|
|33|정규|강화학습 이론 및 실습|Oct 25 2019|`참석`|
|34|특강|영상처리 및 현업에서의 딥러닝 수요 및 전망|Oct 28 2019|`참석`|

---

## Data & Source

### Table of Data & Source

|No|Title|Educational Institution|Source|Remarks|
|-:|:--:|:--:|:-:|:--|
|1|Numpy 기초 및 CNN 기초|<small>AI 이노베이션 스퀘어</small>|[Activation_Function.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/Activation_Function.ipynb)|`Activation_Function`|
|2|CNN 기초 및 Python Open CV 실습|<small>AI 이노베이션 스퀘어</small>|[Introduction_to_convnets.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/Introduction_to_convnets.ipynb)|`Introduction_to_convnets`|
|3|CNN 기초 및 Python Open CV 실습|<small>AI 이노베이션 스퀘어</small>|[HelloCV.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/HelloCV.ipynb)|`HelloCV`|
|4|이진분류, 값 예측 딥 러닝 네트워크 설계|<small>AI 이노베이션 스퀘어</small>|[Boston_House_price_prediction_실습.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/Boston_House_price_prediction_실습.ipynb)|`보스턴집값`|
|5|이진분류, 값 예측 딥 러닝 네트워크 설계|<small>AI 이노베이션 스퀘어</small>|[IMDB_classification_실습.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/IMDB_classification_실습.ipynb)|`영화평점`|
|6|Flicker api를 이용한 데이터 수집 및 VGG 네트워크 활용|<small>AI 이노베이션 스퀘어</small>|[Flicker_application_실습.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/Flicker_application_실습.ipynb)|`Flicker`|
|7|Flicker api를 이용한 데이터 수집 및 VGG 네트워크 활용|<small>AI 이노베이션 스퀘어</small>|[VGG4smalldataset_실습.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/VGG4smalldataset_실습.ipynb)|`Flicker`|
|8|Flicker api를 이용한 데이터 수집 및 VGG 네트워크 활용|<small>AI 이노베이션 스퀘어</small>|[VGG_application_실습.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/VGG_application_실습.ipynb)|`Flicker`|
|9|자기 부호화기 Autoencoder 활용하기|<small>AI 이노베이션 스퀘어</small>|[AutoEncoder.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/AutoEncoder.ipynb)|`AutoEncoder`|
|10|자기 부호화기 Autoencoder 활용하기|<small>AI 이노베이션 스퀘어</small>|[Augmentation.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/Augmentation.ipynb)|`Augmentation`|
|11|자기 부호화기 Autoencoder 활용하기|<small>AI 이노베이션 스퀘어</small>|[Convolutional_Autoencoder.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/Convolutional_Autoencoder.ipynb)|`Convolutional_Autoencoder`|
|12|뉴럴 네트워크 훈련 기법|<small>AI 이노베이션 스퀘어</small>|[Weight_Initialization.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/Weight_Initialization.ipynb)|`Weight_Initialization`|
|13|CNN REVIEW|<small>AI 이노베이션 스퀘어</small>|[MNIST_Dense_example.ipynb](https://github.com/shpimit/shpimit.github.io/blob/master/_pages/AI/Keras/src/KOIPA-Vision/MNIST_Dense_example.ipynb)|`MNIST_Dense_example`|

---

## 1. Unet
* Image : pixel(0~255) 값 / 255 (max normalization) 나누어서 0~1 사이의 값을 가진다.
* Convolution Filter : 3 * 3(대부분의 3 by 3 을 사용한다)
* Feature Map : 컨볼류션을 거치고 나온 값은 0~1사이의 값이 아니고 그 범위를 넘어서 특징(Feature) 이라고 부른다
* Subsampling : Max-Pooling을 의미 한다.
* Back Propagation : 미분하면서 계속해서 값을 바꾸어 가면서 전달된다.
* Lenet
* Unet이 성능이 좋은 이유는 Skip Connection

## 2. Fit vs Fit Generator 
* step_per_epoch  =250
* Image 100G 처럼 데이터 클경우 메모리에 올릴수 없으므로 미리 Batch를 만들어서 올린다.

## 3. Segmentation
* 정답 과 Prediction(모든 Pixel에 대하여 확률값)을 비교하는것

## [4. Lung Segmentation, Cropping, & ResUNet (tf.keras)](https://www.kaggle.com/shpimit/lung-segmentation-cropping-resunet-tf-keras/edit)

* `특징: MaxPooling이 없음`
* Resdual Block : Conv2D → BN → ReLU → Conv → Addition

```python
def bn_act         # BN → ReLU 묶어 놓은 함수
def conv_block     # BN → ReLU → Conv 묶어 놓은 함수
def stem           # Conv2D → BN → ReLU → Conv + shortcut
    shortcut =     # Input → Conv2D
def resudual_block # BN → ReLU → Conv → res   
def ResUNet        # f : Filter의 갯수를 리스트로 만들어 놓고 갖다가 씀.
def dice_loss      # Loss = 1 - IOU(Interest of Unit : 관심지역)  cf : 변형 lnIOU
def dsc            # dice similarity  IOU  교집합/합집합   Predition 0 1 1 1 0 3
    intersection   # 2개 겹친 부분의 값을  reduce_sum      Y         0 1 1 0 0 2       
    smooth         # 0 으로 나누어지 는 것을 방지하기 위해 
```
* CE(Cross Entropy) : -log(Pt)
* FL(Focal Loss) : -(1-pt)r log(pt)  # r(감마)를 줌으로서 미분을 하면, 지수가 앞으로 나와서 에러의 값을 올려준다.

---

## 5. GAN
* Discriminator
* Generator
* Linear → Keras 의 Dense
* 출력 : 0 (가짜),  1(진짜)
* Generator
* 출력 : -1 ~ 1

## 6. WGAN
* GAN  → 1 : 진짜 /  0:가짜
* WGAN → 1 : 진짜 / -1:가짜
* GAN  → (D(x), 1) + (D(G(z)), 0)
*      └ -log(D(x)) -log(1-D(G(z)))
* WGAN → D(x~)) - D(x)   : 값의 범의를 두지 않음으로서, 차이를 2가 생기께끔 하여 더 구별이 잘되게끔 한다.

## Reference

* [KoNLPy](https://konlpy-ko.readthedocs.io/)


```shell
for layer in pretrained_densenet.layers:
    layer.trainable = True

denseNetOutpu = pretrained_densenet.get_layer('relu').output

Feature_Flatten = GlobalAveragePooling2D()(denseNetOutput)
dense1 = Dense(1024, name='dense1', activation='relu', kernel_initializer='he_normal')(Feature_Flatten)
dense1 = BatchNormalization()(dense1)
dense2 = Dense(1024, name='dense2', activation='relu', kernel_initializer='he_normal')(dense1)
dense2 = Dropout(0.3)(dense2)
predictions = Dense(6, name='last', activation='softrmax')(dense2)

New_DenseNet = Model(inputs=pretrained_densenet.input, outputs=predections)
New_DenseNet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
New_DenseNet.summary()
```
