{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import csv # csv file format 달기 위함\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data : names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name total : 1219\n",
      "maximum name length : 11\n"
     ]
    }
   ],
   "source": [
    "data_name = set()      # name set\n",
    "max_len = 0            # maximum length\n",
    "with open('../data/woman_name_dataset.csv') as csv_file: \n",
    "    csv_reader = csv.reader(csv_file, delimiter=',') \n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1      # 첫 line은 컬러명이라서 의미가 없어서.\n",
    "        else:\n",
    "            tmp_name = row[1].split()[0]        # split은 중간의 공백을 구별해서. 리스트로 반납   rddrrrr r\n",
    "            data_name.add(row[1].split()[0])\n",
    "            if len(tmp_name) > max_len:\n",
    "                max_len = len(tmp_name)         # 데이터 중 최대의 길이로 셋팅\n",
    "data_name = list(data_name)                     # set보다는 list가 편해서..\n",
    "print('name total : {}'.format(len(data_name)))\n",
    "print('maximum name length : {}'.format(max_len))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data : Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 alphabets :  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# 문자를 숫자로.. one hot vector로   preprocessing\n",
    "chars = set()     # = {a,b,.....,z}\n",
    "for name in data_name:\n",
    "    for char in name:\n",
    "        chars.add(char)\n",
    "chars = list(np.sort(list(chars)))      # no.sort는   numpy array 로 되어서\n",
    "print('{} alphabets : '.format(len(chars)), chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to convert name to onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_onehot(names, chars, max_len):\n",
    "    # len(names) : batch size\n",
    "    onehot = np.zeros((len(names), max_len, len(chars)+1))      #  이름이 끝나는 것에  signal을 주고 싶어서 Tom마지막 , placeholder에 같은 크기\n",
    "    for idx_1, name in enumerate(names):           # idx_1는 이름의 갯수\n",
    "        for idx_2 in range(max_len):               # idx_2는 이름의 char 갯수\n",
    "            if idx_2 < len(name):\n",
    "                idx_3 = chars.index(name[idx_2])  # idx3 전체 albartbet의 몇번째인가.\n",
    "                onehot[idx_1, idx_2, idx_3] = 1\n",
    "            else:\n",
    "                onehot[idx_1, idx_2, -1] = 1       #  -1 을 주면  onehot이 끝나는것\n",
    "    return onehot\n",
    "\n",
    "onehot_ex = name_to_onehot(['jane'], chars, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dimension and Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = len(data_name)\n",
    "seq_len = max_len - 1\n",
    "dim_data = len(chars) + 1   #  size of the one-hot vecotr.\n",
    "\n",
    "ph_input_name = tf.placeholder(dtype=tf.float32, shape=[None, seq_len, dim_data])   # batch size, maximum seqence 길이,  onehot 길이\n",
    "ph_output_name = tf.placeholder(dtype=tf.float32, shape=[None, seq_len, dim_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define weight variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_rnn_cell = 128   # hideen layer를  ......\n",
    "stddev = 0.02\n",
    "\n",
    "with tf.variable_scope('weights'):   # variable_scope를 담는 통 ( 일반적인 w1, w2, w3를 쓰면..헷갈리단..  variable_scope안의 w1, w2, w3)\n",
    "    W_i = tf.get_variable('W_i', dtype=tf.float32,\n",
    "                         initializer=tf.random_normal([dim_data, dim_rnn_cell],\n",
    "                         stddev = stddev))\n",
    "    # data : 1 by dim_data\n",
    "    # W_i : dim_data by dim_rnn_cell\n",
    "    b_i = tf.get_variable('b_i', dtype=tf.float32,\n",
    "                         initializer=tf.random_normal([dim_rnn_cell],\n",
    "                         stddev = stddev))\n",
    "    \n",
    "    # b_i : 1 by dim_rnn_cell\n",
    "    # h= data * W_i * b_i : batch by dim_data * dim_data by dim_rnn cell +1 1 by dim_rnn_cell\n",
    "    # h : 1 by dim_rnn_cell\n",
    "    W_o = tf.get_variable('W_o', dtype=tf.float32,\n",
    "                         initializer=tf.random_normal([dim_rnn_cell, dim_data],\n",
    "                         stddev = stddev))\n",
    "    b_o = tf.get_variable('b_o', dtype=tf.float32,\n",
    "                         initializer=tf.random_normal([dim_data],\n",
    "                         stddev = stddev))\n",
    "    \n",
    "    # LSTM : batch by dim_rnn_cell : batch  by dim_data\n",
    "    # I want one hot encoding vector!\n",
    "    # LSTM CELL * W_o(dim_rnn_cell by dim_data) + b_o(dim_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RNN for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_dim_rnn_cell  : LSTM Hidden Cell Size\n",
    "def name_rnn_train(_x, _seq_len, _dim_data, _dim_rnn_cell):\n",
    "    # _x : ph_input_name : Batch(0), seq_len(1), dim_data(2)\n",
    "    _x_split = tf.transpose(_x, [1, 0, 2]) # seq_len, batch, dim_data\n",
    "    _x_split = tf.reshape(_x_split, [-1, _dim_data])\n",
    "    \n",
    "    # x_split : seq_len*batch by dim_data\n",
    "    # use tf.AUTO_REUSE,\n",
    "    # Load Variables\n",
    "    with tf.variable_scope('weights', reuse= tf.AUTO_REUSE):\n",
    "        _W_i = tf.get_variable('W_i')\n",
    "        _b_i = tf.get_variable('b_i')\n",
    "        _W_o = tf.get_variable('W_o')\n",
    "        _b_o = tf.get_variable('b_o')\n",
    "    # Linear Operation for Input\n",
    "    _h_split = tf.matmul(_x_split, _W_i) + b_i\n",
    "    _h_split = tf.split(_h_split, _seq_len, axis=0)\n",
    "    \n",
    "    # Define LSTM Cell && RNN\n",
    "    with tf.variable_scope('rnn', reuse=tf.AUTO_REUSE):\n",
    "        _rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(_dim_rnn_cell)\n",
    "        _output, _state = tf.nn.static_rnn(_rnn_cell, _h_split, dtype=tf.float32)\n",
    "    \n",
    "    _total_out = []\n",
    "    \n",
    "    for _tmp_out in _output:\n",
    "        _tmp_out = tf.matmul(_tmp_out, _W_o) + _b_o\n",
    "        _total_out.append(_tmp_out)\n",
    "        \n",
    "    return tf.transpose(tf.stack(_total_out), [1, 0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define result graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_shape : (?, 10, 27)\n"
     ]
    }
   ],
   "source": [
    "result_name = name_rnn_train(ph_input_name, seq_len, dim_data, dim_rnn_cell)\n",
    "print('result_shape :', result_name.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_loss(_gt_name, _result_name, _seq_len):\n",
    "    total_loss = 0\n",
    "    # _resutl_name  : batch, seq_len, dim_data\n",
    "    # ->bathc, dim_data\n",
    "    # batch by dim_data -> loss calculate\n",
    "    for i in range(_seq_len):\n",
    "        gt_char = _gt_name[:, i, :]          # batch, dim_data\n",
    "        result_char = _result_name[:, i, :] # batch, dim_data\n",
    "        tmp_loss = tf.nn.softmax_cross_entropy_with_logits(labels=gt_char, \n",
    "                                                           logits=result_char)\n",
    "        tmp_loss = tf.reduce_mean(tmp_loss)\n",
    "        total_loss += tmp_loss\n",
    "    return total_loss\n",
    "rnn_loss = name_loss(ph_output_name, result_name, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Optimizer and Get Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now ready to start the session\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(rnn_loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(var_list=tf.trainable_variables())   # 학습이 될수 있는 variabale 이 무엇이나..\n",
    "\n",
    "print('Now ready to start the session')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, train_loss : 28.88234760886744\n",
      "Model saved in file: ./RNN_model/model.ckpt-1\n",
      "epoch : 2, train_loss : 18.6269992025275\n",
      "Model saved in file: ./RNN_model/model.ckpt-2\n",
      "epoch : 3, train_loss : 17.659534353958936\n",
      "Model saved in file: ./RNN_model/model.ckpt-3\n",
      "epoch : 4, train_loss : 17.120001742714333\n",
      "Model saved in file: ./RNN_model/model.ckpt-4\n",
      "epoch : 5, train_loss : 16.72336307324861\n",
      "Model saved in file: ./RNN_model/model.ckpt-5\n",
      "epoch : 6, train_loss : 16.349830225894326\n",
      "Model saved in file: ./RNN_model/model.ckpt-6\n",
      "epoch : 7, train_loss : 16.048421508387516\n",
      "Model saved in file: ./RNN_model/model.ckpt-7\n",
      "epoch : 8, train_loss : 15.76255958958676\n",
      "Model saved in file: ./RNN_model/model.ckpt-8\n",
      "epoch : 9, train_loss : 15.47641242177863\n",
      "Model saved in file: ./RNN_model/model.ckpt-9\n",
      "epoch : 10, train_loss : 15.2146880501195\n",
      "Model saved in file: ./RNN_model/model.ckpt-10\n",
      "epoch : 11, train_loss : 14.931576126500183\n",
      "Model saved in file: ./RNN_model/model.ckpt-11\n",
      "epoch : 12, train_loss : 14.657982173718906\n",
      "Model saved in file: ./RNN_model/model.ckpt-12\n",
      "epoch : 13, train_loss : 14.41134151659514\n",
      "Model saved in file: ./RNN_model/model.ckpt-13\n",
      "epoch : 14, train_loss : 14.167578496431048\n",
      "Model saved in file: ./RNN_model/model.ckpt-14\n",
      "epoch : 15, train_loss : 13.912194302207544\n",
      "Model saved in file: ./RNN_model/model.ckpt-15\n",
      "epoch : 16, train_loss : 13.690634526704486\n",
      "Model saved in file: ./RNN_model/model.ckpt-16\n",
      "epoch : 17, train_loss : 13.52023942847001\n",
      "Model saved in file: ./RNN_model/model.ckpt-17\n",
      "epoch : 18, train_loss : 13.393568540874282\n",
      "Model saved in file: ./RNN_model/model.ckpt-18\n",
      "epoch : 19, train_loss : 13.29529074618691\n",
      "Model saved in file: ./RNN_model/model.ckpt-19\n",
      "epoch : 20, train_loss : 13.192663795069645\n",
      "Model saved in file: ./RNN_model/model.ckpt-20\n",
      "epoch : 21, train_loss : 13.123580731843646\n",
      "Model saved in file: ./RNN_model/model.ckpt-21\n",
      "epoch : 22, train_loss : 13.063399666234067\n",
      "Model saved in file: ./RNN_model/model.ckpt-22\n",
      "epoch : 23, train_loss : 12.950805162128649\n",
      "Model saved in file: ./RNN_model/model.ckpt-23\n",
      "epoch : 24, train_loss : 12.87385458695261\n",
      "Model saved in file: ./RNN_model/model.ckpt-24\n",
      "epoch : 25, train_loss : 12.826507467972608\n",
      "Model saved in file: ./RNN_model/model.ckpt-25\n",
      "epoch : 26, train_loss : 12.725944117495889\n",
      "Model saved in file: ./RNN_model/model.ckpt-26\n",
      "epoch : 27, train_loss : 12.661800986842104\n",
      "Model saved in file: ./RNN_model/model.ckpt-27\n",
      "epoch : 28, train_loss : 12.572609901428223\n",
      "Model saved in file: ./RNN_model/model.ckpt-28\n",
      "epoch : 29, train_loss : 12.502071481002002\n",
      "Model saved in file: ./RNN_model/model.ckpt-29\n",
      "epoch : 30, train_loss : 12.447570449427555\n",
      "Model saved in file: ./RNN_model/model.ckpt-30\n",
      "epoch : 31, train_loss : 12.354412229437578\n",
      "Model saved in file: ./RNN_model/model.ckpt-31\n",
      "epoch : 32, train_loss : 12.265427639609888\n",
      "Model saved in file: ./RNN_model/model.ckpt-32\n",
      "epoch : 33, train_loss : 12.214245444849919\n",
      "Model saved in file: ./RNN_model/model.ckpt-33\n",
      "epoch : 34, train_loss : 12.128501239575838\n",
      "Model saved in file: ./RNN_model/model.ckpt-34\n",
      "epoch : 35, train_loss : 12.044278195029811\n",
      "Model saved in file: ./RNN_model/model.ckpt-35\n",
      "epoch : 36, train_loss : 11.96508096393786\n",
      "Model saved in file: ./RNN_model/model.ckpt-36\n",
      "epoch : 37, train_loss : 11.883403175755552\n",
      "Model saved in file: ./RNN_model/model.ckpt-37\n",
      "epoch : 38, train_loss : 11.806849931415758\n",
      "Model saved in file: ./RNN_model/model.ckpt-38\n",
      "epoch : 39, train_loss : 11.722761907075583\n",
      "Model saved in file: ./RNN_model/model.ckpt-39\n",
      "epoch : 40, train_loss : 11.627640272441663\n",
      "Model saved in file: ./RNN_model/model.ckpt-40\n",
      "epoch : 41, train_loss : 11.536088792901289\n",
      "Model saved in file: ./RNN_model/model.ckpt-41\n",
      "epoch : 42, train_loss : 11.440069851122406\n",
      "Model saved in file: ./RNN_model/model.ckpt-42\n",
      "epoch : 43, train_loss : 11.352227512158848\n",
      "Model saved in file: ./RNN_model/model.ckpt-43\n",
      "epoch : 44, train_loss : 11.264506340026854\n",
      "Model saved in file: ./RNN_model/model.ckpt-44\n",
      "epoch : 45, train_loss : 11.205529815272282\n",
      "Model saved in file: ./RNN_model/model.ckpt-45\n",
      "epoch : 46, train_loss : 11.084731553730213\n",
      "Model saved in file: ./RNN_model/model.ckpt-46\n",
      "epoch : 47, train_loss : 10.989706089622096\n",
      "Model saved in file: ./RNN_model/model.ckpt-47\n",
      "epoch : 48, train_loss : 10.917656195791142\n",
      "Model saved in file: ./RNN_model/model.ckpt-48\n",
      "epoch : 49, train_loss : 10.81281667006643\n",
      "Model saved in file: ./RNN_model/model.ckpt-49\n",
      "epoch : 50, train_loss : 10.74394376654374\n",
      "Model saved in file: ./RNN_model/model.ckpt-50\n",
      "epoch : 51, train_loss : 10.660006472938939\n",
      "Model saved in file: ./RNN_model/model.ckpt-51\n",
      "epoch : 52, train_loss : 10.583453278792533\n",
      "Model saved in file: ./RNN_model/model.ckpt-52\n",
      "epoch : 53, train_loss : 10.498629620200708\n",
      "Model saved in file: ./RNN_model/model.ckpt-53\n",
      "epoch : 54, train_loss : 10.401640390094958\n",
      "Model saved in file: ./RNN_model/model.ckpt-54\n",
      "epoch : 55, train_loss : 10.333252304478698\n",
      "Model saved in file: ./RNN_model/model.ckpt-55\n",
      "epoch : 56, train_loss : 10.261377535368265\n",
      "Model saved in file: ./RNN_model/model.ckpt-56\n",
      "epoch : 57, train_loss : 10.176645479704204\n",
      "Model saved in file: ./RNN_model/model.ckpt-57\n",
      "epoch : 58, train_loss : 10.083495190269067\n",
      "Model saved in file: ./RNN_model/model.ckpt-58\n",
      "epoch : 59, train_loss : 10.010421200802451\n",
      "Model saved in file: ./RNN_model/model.ckpt-59\n",
      "epoch : 60, train_loss : 9.93174056002968\n",
      "Model saved in file: ./RNN_model/model.ckpt-60\n",
      "epoch : 61, train_loss : 9.864012216266833\n",
      "Model saved in file: ./RNN_model/model.ckpt-61\n",
      "epoch : 62, train_loss : 9.794260878311963\n",
      "Model saved in file: ./RNN_model/model.ckpt-62\n",
      "epoch : 63, train_loss : 9.707831131784541\n",
      "Model saved in file: ./RNN_model/model.ckpt-63\n",
      "epoch : 64, train_loss : 9.618537953025418\n",
      "Model saved in file: ./RNN_model/model.ckpt-64\n",
      "epoch : 65, train_loss : 9.56138886903462\n",
      "Model saved in file: ./RNN_model/model.ckpt-65\n",
      "epoch : 66, train_loss : 9.48062465065404\n",
      "Model saved in file: ./RNN_model/model.ckpt-66\n",
      "epoch : 67, train_loss : 9.402303243938245\n",
      "Model saved in file: ./RNN_model/model.ckpt-67\n",
      "epoch : 68, train_loss : 9.33735169862446\n",
      "Model saved in file: ./RNN_model/model.ckpt-68\n",
      "epoch : 69, train_loss : 9.265261097958215\n",
      "Model saved in file: ./RNN_model/model.ckpt-69\n",
      "epoch : 70, train_loss : 9.1894420322619\n",
      "Model saved in file: ./RNN_model/model.ckpt-70\n",
      "epoch : 71, train_loss : 9.12452963778847\n",
      "Model saved in file: ./RNN_model/model.ckpt-71\n",
      "epoch : 72, train_loss : 9.049896691974842\n",
      "Model saved in file: ./RNN_model/model.ckpt-72\n",
      "epoch : 73, train_loss : 9.001408325998408\n",
      "Model saved in file: ./RNN_model/model.ckpt-73\n",
      "epoch : 74, train_loss : 8.913863884775262\n",
      "Model saved in file: ./RNN_model/model.ckpt-74\n",
      "epoch : 75, train_loss : 8.860353871395715\n",
      "Model saved in file: ./RNN_model/model.ckpt-75\n",
      "epoch : 76, train_loss : 8.799816959782653\n",
      "Model saved in file: ./RNN_model/model.ckpt-76\n",
      "epoch : 77, train_loss : 8.724560812899941\n",
      "Model saved in file: ./RNN_model/model.ckpt-77\n",
      "epoch : 78, train_loss : 8.650997161865234\n",
      "Model saved in file: ./RNN_model/model.ckpt-78\n",
      "epoch : 79, train_loss : 8.571906190169486\n",
      "Model saved in file: ./RNN_model/model.ckpt-79\n",
      "epoch : 80, train_loss : 8.521329503310355\n",
      "Model saved in file: ./RNN_model/model.ckpt-80\n",
      "epoch : 81, train_loss : 8.446852081700376\n",
      "Model saved in file: ./RNN_model/model.ckpt-81\n",
      "epoch : 82, train_loss : 8.397269901476408\n",
      "Model saved in file: ./RNN_model/model.ckpt-82\n",
      "epoch : 83, train_loss : 8.32365083694458\n",
      "Model saved in file: ./RNN_model/model.ckpt-83\n",
      "epoch : 84, train_loss : 8.27613017433568\n",
      "Model saved in file: ./RNN_model/model.ckpt-84\n",
      "epoch : 85, train_loss : 8.19275464509663\n",
      "Model saved in file: ./RNN_model/model.ckpt-85\n",
      "epoch : 86, train_loss : 8.130727391493947\n",
      "Model saved in file: ./RNN_model/model.ckpt-86\n",
      "epoch : 87, train_loss : 8.085842609405518\n",
      "Model saved in file: ./RNN_model/model.ckpt-87\n",
      "epoch : 88, train_loss : 8.007001073736893\n",
      "Model saved in file: ./RNN_model/model.ckpt-88\n",
      "epoch : 89, train_loss : 7.954338876824628\n",
      "Model saved in file: ./RNN_model/model.ckpt-89\n",
      "epoch : 90, train_loss : 7.886636909685636\n",
      "Model saved in file: ./RNN_model/model.ckpt-90\n",
      "epoch : 91, train_loss : 7.826610364412005\n",
      "Model saved in file: ./RNN_model/model.ckpt-91\n",
      "epoch : 92, train_loss : 7.76870484101145\n",
      "Model saved in file: ./RNN_model/model.ckpt-92\n",
      "epoch : 93, train_loss : 7.719228568829989\n",
      "Model saved in file: ./RNN_model/model.ckpt-93\n",
      "epoch : 94, train_loss : 7.667482225518478\n",
      "Model saved in file: ./RNN_model/model.ckpt-94\n",
      "epoch : 95, train_loss : 7.609826213435122\n",
      "Model saved in file: ./RNN_model/model.ckpt-95\n",
      "epoch : 96, train_loss : 7.5507249330219475\n",
      "Model saved in file: ./RNN_model/model.ckpt-96\n",
      "epoch : 97, train_loss : 7.488030232881245\n",
      "Model saved in file: ./RNN_model/model.ckpt-97\n",
      "epoch : 98, train_loss : 7.442277858131811\n",
      "Model saved in file: ./RNN_model/model.ckpt-98\n",
      "epoch : 99, train_loss : 7.383285120913857\n",
      "Model saved in file: ./RNN_model/model.ckpt-99\n",
      "epoch : 100, train_loss : 7.345773897672954\n",
      "Model saved in file: ./RNN_model/model.ckpt-100\n",
      "epoch : 101, train_loss : 7.2901706193622795\n",
      "Model saved in file: ./RNN_model/model.ckpt-101\n",
      "epoch : 102, train_loss : 7.237842760587993\n",
      "Model saved in file: ./RNN_model/model.ckpt-102\n",
      "epoch : 103, train_loss : 7.197460626301012\n",
      "Model saved in file: ./RNN_model/model.ckpt-103\n",
      "epoch : 104, train_loss : 7.134299102582428\n",
      "Model saved in file: ./RNN_model/model.ckpt-104\n",
      "epoch : 105, train_loss : 7.080920846838701\n",
      "Model saved in file: ./RNN_model/model.ckpt-105\n",
      "epoch : 106, train_loss : 7.030462039144415\n",
      "Model saved in file: ./RNN_model/model.ckpt-106\n",
      "epoch : 107, train_loss : 6.988008800305817\n",
      "Model saved in file: ./RNN_model/model.ckpt-107\n",
      "epoch : 108, train_loss : 6.946906290556255\n",
      "Model saved in file: ./RNN_model/model.ckpt-108\n",
      "epoch : 109, train_loss : 6.891653788717168\n",
      "Model saved in file: ./RNN_model/model.ckpt-109\n",
      "epoch : 110, train_loss : 6.858407296632466\n",
      "Model saved in file: ./RNN_model/model.ckpt-110\n",
      "epoch : 111, train_loss : 6.8052655772158985\n",
      "Model saved in file: ./RNN_model/model.ckpt-111\n",
      "epoch : 112, train_loss : 6.7650082236842115\n",
      "Model saved in file: ./RNN_model/model.ckpt-112\n",
      "epoch : 113, train_loss : 6.71976493534289\n",
      "Model saved in file: ./RNN_model/model.ckpt-113\n",
      "epoch : 114, train_loss : 6.6692928765949455\n",
      "Model saved in file: ./RNN_model/model.ckpt-114\n",
      "epoch : 115, train_loss : 6.639791915291233\n",
      "Model saved in file: ./RNN_model/model.ckpt-115\n",
      "epoch : 116, train_loss : 6.605656648937024\n",
      "Model saved in file: ./RNN_model/model.ckpt-116\n",
      "epoch : 117, train_loss : 6.5564421603554175\n",
      "Model saved in file: ./RNN_model/model.ckpt-117\n",
      "epoch : 118, train_loss : 6.510971797140021\n",
      "Model saved in file: ./RNN_model/model.ckpt-118\n",
      "epoch : 119, train_loss : 6.47663618388929\n",
      "Model saved in file: ./RNN_model/model.ckpt-119\n",
      "epoch : 120, train_loss : 6.435058894910311\n",
      "Model saved in file: ./RNN_model/model.ckpt-120\n",
      "epoch : 121, train_loss : 6.3965314312985075\n",
      "Model saved in file: ./RNN_model/model.ckpt-121\n",
      "epoch : 122, train_loss : 6.362196244691547\n",
      "Model saved in file: ./RNN_model/model.ckpt-122\n",
      "epoch : 123, train_loss : 6.316203242854068\n",
      "Model saved in file: ./RNN_model/model.ckpt-123\n",
      "epoch : 124, train_loss : 6.286868496945028\n",
      "Model saved in file: ./RNN_model/model.ckpt-124\n",
      "epoch : 125, train_loss : 6.242510067789178\n",
      "Model saved in file: ./RNN_model/model.ckpt-125\n",
      "epoch : 126, train_loss : 6.219652803320635\n",
      "Model saved in file: ./RNN_model/model.ckpt-126\n",
      "epoch : 127, train_loss : 6.190161880693937\n",
      "Model saved in file: ./RNN_model/model.ckpt-127\n",
      "epoch : 128, train_loss : 6.1480917177702255\n",
      "Model saved in file: ./RNN_model/model.ckpt-128\n",
      "epoch : 129, train_loss : 6.111247037586413\n",
      "Model saved in file: ./RNN_model/model.ckpt-129\n",
      "epoch : 130, train_loss : 6.081362674110815\n",
      "Model saved in file: ./RNN_model/model.ckpt-130\n",
      "epoch : 131, train_loss : 6.054022161584151\n",
      "Model saved in file: ./RNN_model/model.ckpt-131\n",
      "epoch : 132, train_loss : 6.02355758767379\n",
      "Model saved in file: ./RNN_model/model.ckpt-132\n",
      "epoch : 133, train_loss : 5.991408373180189\n",
      "Model saved in file: ./RNN_model/model.ckpt-133\n",
      "epoch : 134, train_loss : 5.967622505991082\n",
      "Model saved in file: ./RNN_model/model.ckpt-134\n",
      "epoch : 135, train_loss : 5.959697271648206\n",
      "Model saved in file: ./RNN_model/model.ckpt-135\n",
      "epoch : 136, train_loss : 5.914266912560715\n",
      "Model saved in file: ./RNN_model/model.ckpt-136\n",
      "epoch : 137, train_loss : 5.873075485229493\n",
      "Model saved in file: ./RNN_model/model.ckpt-137\n",
      "epoch : 138, train_loss : 5.851713205638684\n",
      "Model saved in file: ./RNN_model/model.ckpt-138\n",
      "epoch : 139, train_loss : 5.8298776777167065\n",
      "Model saved in file: ./RNN_model/model.ckpt-139\n",
      "epoch : 140, train_loss : 5.794826181311357\n",
      "Model saved in file: ./RNN_model/model.ckpt-140\n",
      "epoch : 141, train_loss : 5.777587463981226\n",
      "Model saved in file: ./RNN_model/model.ckpt-141\n",
      "epoch : 142, train_loss : 5.746028498599403\n",
      "Model saved in file: ./RNN_model/model.ckpt-142\n",
      "epoch : 143, train_loss : 5.725667200590435\n",
      "Model saved in file: ./RNN_model/model.ckpt-143\n",
      "epoch : 144, train_loss : 5.704853760568719\n",
      "Model saved in file: ./RNN_model/model.ckpt-144\n",
      "epoch : 145, train_loss : 5.681902684663472\n",
      "Model saved in file: ./RNN_model/model.ckpt-145\n",
      "epoch : 146, train_loss : 5.646559037660298\n",
      "Model saved in file: ./RNN_model/model.ckpt-146\n",
      "epoch : 147, train_loss : 5.6308164847524536\n",
      "Model saved in file: ./RNN_model/model.ckpt-147\n",
      "epoch : 148, train_loss : 5.6113778917413\n",
      "Model saved in file: ./RNN_model/model.ckpt-148\n",
      "epoch : 149, train_loss : 5.5798296175505\n",
      "Model saved in file: ./RNN_model/model.ckpt-149\n",
      "epoch : 150, train_loss : 5.56727459556178\n",
      "Model saved in file: ./RNN_model/model.ckpt-150\n",
      "epoch : 151, train_loss : 5.546431240282561\n",
      "Model saved in file: ./RNN_model/model.ckpt-151\n",
      "epoch : 152, train_loss : 5.523883844676769\n",
      "Model saved in file: ./RNN_model/model.ckpt-152\n",
      "epoch : 153, train_loss : 5.506038590481407\n",
      "Model saved in file: ./RNN_model/model.ckpt-153\n",
      "epoch : 154, train_loss : 5.491564725574694\n",
      "Model saved in file: ./RNN_model/model.ckpt-154\n",
      "epoch : 155, train_loss : 5.467124738191302\n",
      "Model saved in file: ./RNN_model/model.ckpt-155\n",
      "epoch : 156, train_loss : 5.443775453065571\n",
      "Model saved in file: ./RNN_model/model.ckpt-156\n",
      "epoch : 157, train_loss : 5.421084981215627\n",
      "Model saved in file: ./RNN_model/model.ckpt-157\n",
      "epoch : 158, train_loss : 5.423319063688581\n",
      "Model saved in file: ./RNN_model/model.ckpt-158\n",
      "epoch : 159, train_loss : 5.397743425871197\n",
      "Model saved in file: ./RNN_model/model.ckpt-159\n",
      "epoch : 160, train_loss : 5.383857325503699\n",
      "Model saved in file: ./RNN_model/model.ckpt-160\n",
      "epoch : 161, train_loss : 5.374525647414358\n",
      "Model saved in file: ./RNN_model/model.ckpt-161\n",
      "epoch : 162, train_loss : 5.352555199673301\n",
      "Model saved in file: ./RNN_model/model.ckpt-162\n",
      "epoch : 163, train_loss : 5.338991014580977\n",
      "Model saved in file: ./RNN_model/model.ckpt-163\n",
      "epoch : 164, train_loss : 5.317482973399915\n",
      "Model saved in file: ./RNN_model/model.ckpt-164\n",
      "epoch : 165, train_loss : 5.300774674666555\n",
      "Model saved in file: ./RNN_model/model.ckpt-165\n",
      "epoch : 166, train_loss : 5.278806636207983\n",
      "Model saved in file: ./RNN_model/model.ckpt-166\n",
      "epoch : 167, train_loss : 5.2593744177567325\n",
      "Model saved in file: ./RNN_model/model.ckpt-167\n",
      "epoch : 168, train_loss : 5.264723351127222\n",
      "Model saved in file: ./RNN_model/model.ckpt-168\n",
      "epoch : 169, train_loss : 5.239978639703047\n",
      "Model saved in file: ./RNN_model/model.ckpt-169\n",
      "epoch : 170, train_loss : 5.222865606609144\n",
      "Model saved in file: ./RNN_model/model.ckpt-170\n",
      "epoch : 171, train_loss : 5.198700327622263\n",
      "Model saved in file: ./RNN_model/model.ckpt-171\n",
      "epoch : 172, train_loss : 5.186485014463727\n",
      "Model saved in file: ./RNN_model/model.ckpt-172\n",
      "epoch : 173, train_loss : 5.177536286805806\n",
      "Model saved in file: ./RNN_model/model.ckpt-173\n",
      "epoch : 174, train_loss : 5.170638912602475\n",
      "Model saved in file: ./RNN_model/model.ckpt-174\n",
      "epoch : 175, train_loss : 5.150406586496454\n",
      "Model saved in file: ./RNN_model/model.ckpt-175\n",
      "epoch : 176, train_loss : 5.135734382428621\n",
      "Model saved in file: ./RNN_model/model.ckpt-176\n",
      "epoch : 177, train_loss : 5.124523940839266\n",
      "Model saved in file: ./RNN_model/model.ckpt-177\n",
      "epoch : 178, train_loss : 5.114203553450735\n",
      "Model saved in file: ./RNN_model/model.ckpt-178\n",
      "epoch : 179, train_loss : 5.105977133700723\n",
      "Model saved in file: ./RNN_model/model.ckpt-179\n",
      "epoch : 180, train_loss : 5.089974001834266\n",
      "Model saved in file: ./RNN_model/model.ckpt-180\n",
      "epoch : 181, train_loss : 5.078289935463352\n",
      "Model saved in file: ./RNN_model/model.ckpt-181\n",
      "epoch : 182, train_loss : 5.072560034300152\n",
      "Model saved in file: ./RNN_model/model.ckpt-182\n",
      "epoch : 183, train_loss : 5.057972657053094\n",
      "Model saved in file: ./RNN_model/model.ckpt-183\n",
      "epoch : 184, train_loss : 5.044691136008815\n",
      "Model saved in file: ./RNN_model/model.ckpt-184\n",
      "epoch : 185, train_loss : 5.042502604032817\n",
      "Model saved in file: ./RNN_model/model.ckpt-185\n",
      "epoch : 186, train_loss : 5.027126839286403\n",
      "Model saved in file: ./RNN_model/model.ckpt-186\n",
      "epoch : 187, train_loss : 5.026148093374152\n",
      "Model saved in file: ./RNN_model/model.ckpt-187\n",
      "epoch : 188, train_loss : 5.002026808889289\n",
      "Model saved in file: ./RNN_model/model.ckpt-188\n",
      "epoch : 189, train_loss : 5.000458365992496\n",
      "Model saved in file: ./RNN_model/model.ckpt-189\n",
      "epoch : 190, train_loss : 4.979876719023053\n",
      "Model saved in file: ./RNN_model/model.ckpt-190\n",
      "epoch : 191, train_loss : 4.973548512709767\n",
      "Model saved in file: ./RNN_model/model.ckpt-191\n",
      "epoch : 192, train_loss : 4.975726955815365\n",
      "Model saved in file: ./RNN_model/model.ckpt-192\n",
      "epoch : 193, train_loss : 4.963386359967684\n",
      "Model saved in file: ./RNN_model/model.ckpt-193\n",
      "epoch : 194, train_loss : 4.950365869622482\n",
      "Model saved in file: ./RNN_model/model.ckpt-194\n",
      "epoch : 195, train_loss : 4.939387321472168\n",
      "Model saved in file: ./RNN_model/model.ckpt-195\n",
      "epoch : 196, train_loss : 4.943730203728927\n",
      "Model saved in file: ./RNN_model/model.ckpt-196\n",
      "epoch : 197, train_loss : 4.929129098591051\n",
      "Model saved in file: ./RNN_model/model.ckpt-197\n",
      "epoch : 198, train_loss : 4.9202615838301815\n",
      "Model saved in file: ./RNN_model/model.ckpt-198\n",
      "epoch : 199, train_loss : 4.9202090062593165\n",
      "Model saved in file: ./RNN_model/model.ckpt-199\n",
      "epoch : 200, train_loss : 4.902339282788729\n",
      "Model saved in file: ./RNN_model/model.ckpt-200\n",
      "epoch : 201, train_loss : 4.896803755509226\n",
      "Model saved in file: ./RNN_model/model.ckpt-201\n",
      "epoch : 202, train_loss : 4.883091826187937\n",
      "Model saved in file: ./RNN_model/model.ckpt-202\n",
      "epoch : 203, train_loss : 4.8809738159179705\n",
      "Model saved in file: ./RNN_model/model.ckpt-203\n",
      "epoch : 204, train_loss : 4.870889412729364\n",
      "Model saved in file: ./RNN_model/model.ckpt-204\n",
      "epoch : 205, train_loss : 4.8575966734635205\n",
      "Model saved in file: ./RNN_model/model.ckpt-205\n",
      "epoch : 206, train_loss : 4.8516448924416\n",
      "Model saved in file: ./RNN_model/model.ckpt-206\n",
      "epoch : 207, train_loss : 4.8522500489887435\n",
      "Model saved in file: ./RNN_model/model.ckpt-207\n",
      "epoch : 208, train_loss : 4.855400236029374\n",
      "Model saved in file: ./RNN_model/model.ckpt-208\n",
      "epoch : 209, train_loss : 4.849351431194105\n",
      "Model saved in file: ./RNN_model/model.ckpt-209\n",
      "epoch : 210, train_loss : 4.834192426581133\n",
      "Model saved in file: ./RNN_model/model.ckpt-210\n",
      "epoch : 211, train_loss : 4.830471314881978\n",
      "Model saved in file: ./RNN_model/model.ckpt-211\n",
      "epoch : 212, train_loss : 4.816604990708201\n",
      "Model saved in file: ./RNN_model/model.ckpt-212\n",
      "epoch : 213, train_loss : 4.813752099087363\n",
      "Model saved in file: ./RNN_model/model.ckpt-213\n",
      "epoch : 214, train_loss : 4.818528024773849\n",
      "Model saved in file: ./RNN_model/model.ckpt-214\n",
      "epoch : 215, train_loss : 4.798924847653038\n",
      "Model saved in file: ./RNN_model/model.ckpt-215\n",
      "epoch : 216, train_loss : 4.800941266511615\n",
      "Model saved in file: ./RNN_model/model.ckpt-216\n",
      "epoch : 217, train_loss : 4.789627853192781\n",
      "Model saved in file: ./RNN_model/model.ckpt-217\n",
      "epoch : 218, train_loss : 4.781093296251799\n",
      "Model saved in file: ./RNN_model/model.ckpt-218\n",
      "epoch : 219, train_loss : 4.78604733316522\n",
      "Model saved in file: ./RNN_model/model.ckpt-219\n",
      "epoch : 220, train_loss : 4.780632445686742\n",
      "Model saved in file: ./RNN_model/model.ckpt-220\n",
      "epoch : 221, train_loss : 4.770376782668263\n",
      "Model saved in file: ./RNN_model/model.ckpt-221\n",
      "epoch : 222, train_loss : 4.7636329500298755\n",
      "Model saved in file: ./RNN_model/model.ckpt-222\n",
      "epoch : 223, train_loss : 4.764173306916889\n",
      "Model saved in file: ./RNN_model/model.ckpt-223\n",
      "epoch : 224, train_loss : 4.758184483176784\n",
      "Model saved in file: ./RNN_model/model.ckpt-224\n",
      "epoch : 225, train_loss : 4.754288271853799\n",
      "Model saved in file: ./RNN_model/model.ckpt-225\n",
      "epoch : 226, train_loss : 4.753107296793084\n",
      "Model saved in file: ./RNN_model/model.ckpt-226\n",
      "epoch : 227, train_loss : 4.744985655734414\n",
      "Model saved in file: ./RNN_model/model.ckpt-227\n",
      "epoch : 228, train_loss : 4.740304971996106\n",
      "Model saved in file: ./RNN_model/model.ckpt-228\n",
      "epoch : 229, train_loss : 4.730224433698152\n",
      "Model saved in file: ./RNN_model/model.ckpt-229\n",
      "epoch : 230, train_loss : 4.72966174075478\n",
      "Model saved in file: ./RNN_model/model.ckpt-230\n",
      "epoch : 231, train_loss : 4.724961331016139\n",
      "Model saved in file: ./RNN_model/model.ckpt-231\n",
      "epoch : 232, train_loss : 4.724763820045872\n",
      "Model saved in file: ./RNN_model/model.ckpt-232\n",
      "epoch : 233, train_loss : 4.719883743085359\n",
      "Model saved in file: ./RNN_model/model.ckpt-233\n",
      "epoch : 234, train_loss : 4.715274308857166\n",
      "Model saved in file: ./RNN_model/model.ckpt-234\n",
      "epoch : 235, train_loss : 4.70762804934853\n",
      "Model saved in file: ./RNN_model/model.ckpt-235\n",
      "epoch : 236, train_loss : 4.7023653984069815\n",
      "Model saved in file: ./RNN_model/model.ckpt-236\n",
      "epoch : 237, train_loss : 4.6993486253838785\n",
      "Model saved in file: ./RNN_model/model.ckpt-237\n",
      "epoch : 238, train_loss : 4.704232768008583\n",
      "Model saved in file: ./RNN_model/model.ckpt-238\n",
      "epoch : 239, train_loss : 4.706562293203254\n",
      "Model saved in file: ./RNN_model/model.ckpt-239\n",
      "epoch : 240, train_loss : 4.6888444549159\n",
      "Model saved in file: ./RNN_model/model.ckpt-240\n",
      "epoch : 241, train_loss : 4.690007109391062\n",
      "Model saved in file: ./RNN_model/model.ckpt-241\n",
      "epoch : 242, train_loss : 4.678484916687012\n",
      "Model saved in file: ./RNN_model/model.ckpt-242\n",
      "epoch : 243, train_loss : 4.674560095134534\n",
      "Model saved in file: ./RNN_model/model.ckpt-243\n",
      "epoch : 244, train_loss : 4.674003425397371\n",
      "Model saved in file: ./RNN_model/model.ckpt-244\n",
      "epoch : 245, train_loss : 4.6703734397888175\n",
      "Model saved in file: ./RNN_model/model.ckpt-245\n",
      "epoch : 246, train_loss : 4.670478870994166\n",
      "Model saved in file: ./RNN_model/model.ckpt-246\n",
      "epoch : 247, train_loss : 4.665914359845613\n",
      "Model saved in file: ./RNN_model/model.ckpt-247\n",
      "epoch : 248, train_loss : 4.663475413071481\n",
      "Model saved in file: ./RNN_model/model.ckpt-248\n",
      "epoch : 249, train_loss : 4.6565738226238045\n",
      "Model saved in file: ./RNN_model/model.ckpt-249\n",
      "epoch : 250, train_loss : 4.655475139617919\n",
      "Model saved in file: ./RNN_model/model.ckpt-250\n",
      "epoch : 251, train_loss : 4.661262938850805\n",
      "Model saved in file: ./RNN_model/model.ckpt-251\n",
      "epoch : 252, train_loss : 4.650692211954218\n",
      "Model saved in file: ./RNN_model/model.ckpt-252\n",
      "epoch : 253, train_loss : 4.643667045392489\n",
      "Model saved in file: ./RNN_model/model.ckpt-253\n",
      "epoch : 254, train_loss : 4.636515943627608\n",
      "Model saved in file: ./RNN_model/model.ckpt-254\n",
      "epoch : 255, train_loss : 4.641063439218622\n",
      "Model saved in file: ./RNN_model/model.ckpt-255\n",
      "epoch : 256, train_loss : 4.637724374469958\n",
      "Model saved in file: ./RNN_model/model.ckpt-256\n",
      "epoch : 257, train_loss : 4.636434580150403\n",
      "Model saved in file: ./RNN_model/model.ckpt-257\n",
      "epoch : 258, train_loss : 4.626754334098415\n",
      "Model saved in file: ./RNN_model/model.ckpt-258\n",
      "epoch : 259, train_loss : 4.632980346679687\n",
      "Model saved in file: ./RNN_model/model.ckpt-259\n",
      "epoch : 260, train_loss : 4.625953599026328\n",
      "Model saved in file: ./RNN_model/model.ckpt-260\n",
      "epoch : 261, train_loss : 4.623058394381875\n",
      "Model saved in file: ./RNN_model/model.ckpt-261\n",
      "epoch : 262, train_loss : 4.612949697594894\n",
      "Model saved in file: ./RNN_model/model.ckpt-262\n",
      "epoch : 263, train_loss : 4.609185996808503\n",
      "Model saved in file: ./RNN_model/model.ckpt-263\n",
      "epoch : 264, train_loss : 4.615394491898386\n",
      "Model saved in file: ./RNN_model/model.ckpt-264\n",
      "epoch : 265, train_loss : 4.6094802053351165\n",
      "Model saved in file: ./RNN_model/model.ckpt-265\n",
      "epoch : 266, train_loss : 4.608047234384637\n",
      "Model saved in file: ./RNN_model/model.ckpt-266\n",
      "epoch : 267, train_loss : 4.608236764606676\n",
      "Model saved in file: ./RNN_model/model.ckpt-267\n",
      "epoch : 268, train_loss : 4.60210923144692\n",
      "Model saved in file: ./RNN_model/model.ckpt-268\n",
      "epoch : 269, train_loss : 4.594307196767707\n",
      "Model saved in file: ./RNN_model/model.ckpt-269\n",
      "epoch : 270, train_loss : 4.603555829901445\n",
      "Model saved in file: ./RNN_model/model.ckpt-270\n",
      "epoch : 271, train_loss : 4.597077821430407\n",
      "Model saved in file: ./RNN_model/model.ckpt-271\n",
      "epoch : 272, train_loss : 4.593521168357448\n",
      "Model saved in file: ./RNN_model/model.ckpt-272\n",
      "epoch : 273, train_loss : 4.5939915054722835\n",
      "Model saved in file: ./RNN_model/model.ckpt-273\n",
      "epoch : 274, train_loss : 4.595139152125308\n",
      "Model saved in file: ./RNN_model/model.ckpt-274\n",
      "epoch : 275, train_loss : 4.600436511792633\n",
      "Model saved in file: ./RNN_model/model.ckpt-275\n",
      "epoch : 276, train_loss : 4.60313290043881\n",
      "Model saved in file: ./RNN_model/model.ckpt-276\n",
      "epoch : 277, train_loss : 4.589922679098028\n",
      "Model saved in file: ./RNN_model/model.ckpt-277\n",
      "epoch : 278, train_loss : 4.573727607727051\n",
      "Model saved in file: ./RNN_model/model.ckpt-278\n",
      "epoch : 279, train_loss : 4.578500597100508\n",
      "Model saved in file: ./RNN_model/model.ckpt-279\n",
      "epoch : 280, train_loss : 4.5803439742640455\n",
      "Model saved in file: ./RNN_model/model.ckpt-280\n",
      "epoch : 281, train_loss : 4.578212110619797\n",
      "Model saved in file: ./RNN_model/model.ckpt-281\n",
      "epoch : 282, train_loss : 4.569742077275326\n",
      "Model saved in file: ./RNN_model/model.ckpt-282\n",
      "epoch : 283, train_loss : 4.574651366785953\n",
      "Model saved in file: ./RNN_model/model.ckpt-283\n",
      "epoch : 284, train_loss : 4.577548704649272\n",
      "Model saved in file: ./RNN_model/model.ckpt-284\n",
      "epoch : 285, train_loss : 4.570560605902422\n",
      "Model saved in file: ./RNN_model/model.ckpt-285\n",
      "epoch : 286, train_loss : 4.567535099230315\n",
      "Model saved in file: ./RNN_model/model.ckpt-286\n",
      "epoch : 287, train_loss : 4.5695067706860995\n",
      "Model saved in file: ./RNN_model/model.ckpt-287\n",
      "epoch : 288, train_loss : 4.560104570890728\n",
      "Model saved in file: ./RNN_model/model.ckpt-288\n",
      "epoch : 289, train_loss : 4.5579379232306225\n",
      "Model saved in file: ./RNN_model/model.ckpt-289\n",
      "epoch : 290, train_loss : 4.5630634709408415\n",
      "Model saved in file: ./RNN_model/model.ckpt-290\n",
      "epoch : 291, train_loss : 4.556521164743524\n",
      "Model saved in file: ./RNN_model/model.ckpt-291\n",
      "epoch : 292, train_loss : 4.555634122145804\n",
      "Model saved in file: ./RNN_model/model.ckpt-292\n",
      "epoch : 293, train_loss : 4.556780890414589\n",
      "Model saved in file: ./RNN_model/model.ckpt-293\n",
      "epoch : 294, train_loss : 4.559654035066304\n",
      "Model saved in file: ./RNN_model/model.ckpt-294\n",
      "epoch : 295, train_loss : 4.558537583602102\n",
      "Model saved in file: ./RNN_model/model.ckpt-295\n",
      "epoch : 296, train_loss : 4.548728189970317\n",
      "Model saved in file: ./RNN_model/model.ckpt-296\n",
      "epoch : 297, train_loss : 4.5539240084196395\n",
      "Model saved in file: ./RNN_model/model.ckpt-297\n",
      "epoch : 298, train_loss : 4.549852120248895\n",
      "Model saved in file: ./RNN_model/model.ckpt-298\n",
      "epoch : 299, train_loss : 4.545313609273811\n",
      "Model saved in file: ./RNN_model/model.ckpt-299\n",
      "epoch : 300, train_loss : 4.547696414746737\n",
      "Model saved in file: ./RNN_model/model.ckpt-300\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 300\n",
    "batch_size = 64\n",
    "num_batch = int(num_data/batch_size)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for _epoch in range(max_epoch):\n",
    "        random.seed(_epoch)\n",
    "        batch_shuffle = list(range(num_data))\n",
    "        random.shuffle(batch_shuffle)\n",
    "        \n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for i in range(num_batch):\n",
    "            batch_idx = [batch_shuffle[idx] for idx in range(i*batch_size,\n",
    "                                                            (i+1)*batch_size)]\n",
    "            batch_names = [name for name in data_name if data_name.index(name) in batch_idx]\n",
    "            batch_onehots = name_to_onehot(batch_names, chars, max_len)\n",
    "            \n",
    "            input_onehot = batch_onehots[:, 0:(max_len-1), :]   # a b y s\n",
    "            output_onehot = batch_onehots[:, 1:max_len, :]      # b y s\n",
    "\n",
    "            train_feed_dict = {ph_input_name: input_onehot, \n",
    "                               ph_output_name: output_onehot}\n",
    "            \n",
    "            sess.run(optimizer, feed_dict = train_feed_dict)\n",
    "            curr_loss = sess.run(rnn_loss, feed_dict=train_feed_dict)\n",
    "            \n",
    "            total_train_loss += curr_loss/num_batch\n",
    "\n",
    "        print('epoch : {}, train_loss : {}'.format(_epoch+1, total_train_loss))\n",
    "        \n",
    "        model_save_path = saver.save(sess, './RNN_model/model.ckpt', global_step=_epoch+1)\n",
    "        print('Model saved in file: {}'.format(model_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RNN to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_test_input_name = tf.placeholder(dtype=tf.float32, shape=[1, 1, dim_data])\n",
    "# hideen  size : 1 \n",
    "ph_h = tf.placeholder(dtype=tf.float32, shape=[1, dim_rnn_cell])\n",
    "# hideen stat of LSTM\n",
    "ph_c = tf.placeholder(dtype=tf.float32, shape=[1, dim_rnn_cell])\n",
    "# cell state of LSTM\n",
    "\n",
    "def name_rnn_test(_x, _dim_data, _dim_rnn_cell, _prev_h, _prev_c):  # ph_h, ph_c\n",
    "    _x_split = tf.transpose(_x, [1, 0, 2]) # seq_len, batch, dim_data\n",
    "    _x_split = tf.reshape(_x_split, [-1, _dim_data])\n",
    "    \n",
    "    with tf.variable_scope('weights', reuse=tf.AUTO_REUSE):\n",
    "        _W_i = tf.get_variable('W_i')\n",
    "        _b_i = tf.get_variable('b_i')\n",
    "        \n",
    "        _W_o = tf.get_variable('W_o')\n",
    "        _b_o = tf.get_variable('b_o')\n",
    "        \n",
    "    _h_split = tf.matmul(_x_split, _W_i) + b_i\n",
    "    _h_split = tf.split(_h_split, 1, axis=0) # 1 is the seq_len\n",
    "    \n",
    "    with tf.variable_scope('rnn', reuse=tf.AUTO_REUSE):\n",
    "        _rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(_dim_rnn_cell)\n",
    "        _output, _state = tf.nn.static_rnn(_rnn_cell, _h_split, dtype=tf.float32,\n",
    "                                           initial_state = (_prev_h, _prev_c))\n",
    "    _total_out = []\n",
    "    \n",
    "    for _tmp_out in _output:\n",
    "        _tmp_out = tf.matmul(_tmp_out, _W_o) + _b_o\n",
    "        _total_out.append(_tmp_out)\n",
    "        \n",
    "    return tf.transpose(tf.stack(_total_out), [1, 0, 2]), _state  # output _state를다시 쓰기위하여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_name, test_state = name_rnn_test(ph_test_input_name, dim_data, dim_rnn_cell,\n",
    "                                            ph_h, ph_c)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    saver.restore(sess, './RNN_model/model.ckpt-300')\n",
    "    \n",
    "    total_name = ''\n",
    "    prev_char = 'a'\n",
    "    total_name += prev_char\n",
    "    prev_state = (np.zeros((1, dim_rnn_cell)), np.zeros((1, dim_rnn_cell)))\n",
    "    for i in range(seq_len):\n",
    "        input_onehot = np.zeros((1, 1, dim_data)) # make a space\n",
    "        prev_char_idx = chars.index(prev_char)\n",
    "        input_onehot[:, :, prev_char_idx] = 1\n",
    "            \n",
    "        test_feed_dict = {ph_test_input_name: input_onehot,\n",
    "                          ph_h: prev_state[0], ph_c: prev_state[1]}\n",
    "        curr_result, curr_state = sess.run([test_result_name, test_state], test_feed_dict)\n",
    "        if np.argmax(curr_result) == dim_data-1:\n",
    "            break\n",
    "        else:\n",
    "            softmax_result = sess.run(tf.nn.softmax(test_result_name), test_feed_dict)\n",
    "            softmax_result = np.squeeze(softmax_result)\n",
    "            softmax_result = softmax_result[:dim_data-1]/sum(softmax_result[:dim_data-1])\n",
    "            prev_char = np.random.choice(chars, 1, p=softmax_result)\n",
    "            total_name += prev_char[0]\n",
    "            prev_state = curr_state        \n",
    "    print('Result Name :', total_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
