{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing all the require library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path for the data set which is taken from UCI machine library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path='https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data'\n",
    "test_path='https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the columns name for the data set\n",
    "\n",
    "col_names=['s1','c1','s2','c2','s3','c3','s4','c4','s5','c5','class' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the data from path and assigning variables name\n",
    "\n",
    "poker_train=pd.read_table(train_path, sep=',', names=col_names)\n",
    "poker_test=pd.read_table(test_path, sep=',', names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>c1</th>\n",
       "      <th>s2</th>\n",
       "      <th>c2</th>\n",
       "      <th>s3</th>\n",
       "      <th>c3</th>\n",
       "      <th>s4</th>\n",
       "      <th>c4</th>\n",
       "      <th>s5</th>\n",
       "      <th>c5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s1  c1  s2  c2  s3  c3  s4  c4  s5  c5  class\n",
       "0   1  10   1  11   1  13   1  12   1   1      9\n",
       "1   2  11   2  13   2  10   2  12   2   1      9\n",
       "2   3  12   3  11   3  13   3  10   3   1      9\n",
       "3   4  10   4  11   4   1   4  13   4  12      9\n",
       "4   4   1   4  13   4  12   4  11   4  10      9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>c1</th>\n",
       "      <th>s2</th>\n",
       "      <th>c2</th>\n",
       "      <th>s3</th>\n",
       "      <th>c3</th>\n",
       "      <th>s4</th>\n",
       "      <th>c4</th>\n",
       "      <th>s5</th>\n",
       "      <th>c5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s1  c1  s2  c2  s3  c3  s4  c4  s5  c5  class\n",
       "0   1   1   1  13   2   4   2   3   1  12      0\n",
       "1   3  12   3   2   3  11   4   5   2   5      1\n",
       "2   1   9   4   6   1   4   3   2   3   9      1\n",
       "3   1   4   3  13   2  13   2   1   3   6      1\n",
       "4   3  10   2   7   1   2   2  11   4   9      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poker_train.head()\n",
    "poker_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=poker_train\n",
    "test=poker_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the suit of cards variables into category\n",
    "\n",
    "col=['s1','s2','s3','s4','s5']\n",
    "for i in col:\n",
    "    train[i]=train[i].astype('category')\n",
    "    test[i]=test[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for the categorical Variable\n",
    "\n",
    "train=pd.get_dummies(train)\n",
    "test=pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>class</th>\n",
       "      <th>s1_1</th>\n",
       "      <th>s1_2</th>\n",
       "      <th>s1_3</th>\n",
       "      <th>s1_4</th>\n",
       "      <th>...</th>\n",
       "      <th>s3_3</th>\n",
       "      <th>s3_4</th>\n",
       "      <th>s4_1</th>\n",
       "      <th>s4_2</th>\n",
       "      <th>s4_3</th>\n",
       "      <th>s4_4</th>\n",
       "      <th>s5_1</th>\n",
       "      <th>s5_2</th>\n",
       "      <th>s5_3</th>\n",
       "      <th>s5_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2  c3  c4  c5  class  s1_1  s1_2  s1_3  s1_4  ...   s3_3  s3_4  s4_1  \\\n",
       "0  10  11  13  12   1      9     1     0     0     0  ...      0     0     1   \n",
       "1  11  13  10  12   1      9     0     1     0     0  ...      0     0     0   \n",
       "2  12  11  13  10   1      9     0     0     1     0  ...      1     0     0   \n",
       "3  10  11   1  13  12      9     0     0     0     1  ...      0     1     0   \n",
       "4   1  13  12  11  10      9     0     0     0     1  ...      0     1     0   \n",
       "\n",
       "   s4_2  s4_3  s4_4  s5_1  s5_2  s5_3  s5_4  \n",
       "0     0     0     0     1     0     0     0  \n",
       "1     1     0     0     0     1     0     0  \n",
       "2     0     1     0     0     0     1     0  \n",
       "3     0     0     1     0     0     0     1  \n",
       "4     0     0     1     0     0     0     1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 26 variables out of which 'class' is the target variable. So, the total number of explantory variables will be 25 and one target variable. Target variable has 10 classes so, first we have to convert it into category and then get dummy variables for classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=np.array(train.drop('class', axis=1))\n",
    "y=pd.get_dummies(train['class'].astype('category'))\n",
    "y_train=np.array(y)\n",
    "\n",
    "x_test=np.array(test.drop('class', axis=1))\n",
    "y1=pd.get_dummies(test['class'].astype('category'))\n",
    "y_test=np.array(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow- Neural Net\n",
    "Here I am using neural net for classification. For that I am considering 3 hidden layers with 500 nodes at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_nodes_hl1=500\n",
    "n_nodes_hl2=500\n",
    "n_nodes_hl3=500\n",
    "\n",
    "n_classes=10\n",
    "\n",
    "x=tf.placeholder('float',[None, 25])\n",
    "y=tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation function- For hidden layers i am considering tanh and for the output layer i am taking softmax. Here i am using Adam optimizer with learning rate 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_model(data):\n",
    "    hl1={'weights':tf.Variable(tf.random_normal([25, n_nodes_hl1])),\n",
    "         'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "    \n",
    "    hl2={'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "         'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "    \n",
    "    hl3={'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "         'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer={'weights':tf.Variable(tf.random_normal([n_nodes_hl3,n_classes])),\n",
    "                  'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    l1=tf.add(tf.matmul(data,hl1['weights']), hl1['biases'])\n",
    "    l1=tf.nn.tanh(l1)\n",
    "    \n",
    "    l2=tf.add(tf.matmul(l1,hl2['weights']), hl2['biases'])\n",
    "    l2=tf.nn.tanh(l2)\n",
    "\n",
    "    l3=tf.add(tf.matmul(l2,hl3['weights']), hl3['biases'])\n",
    "    l3=tf.nn.tanh(l3)\n",
    "    \n",
    "    output=tf.matmul(l3,output_layer['weights'])+ output_layer['biases']\n",
    "    output=tf.nn.softmax(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Model without batch processesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(x):\n",
    "    prediction=nn_model(x)\n",
    "    cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "    \n",
    "    learning_rate= 0.1\n",
    "    optimizer= tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    hm_epochs=10\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss=0\n",
    "            _,c=sess.run([optimizer, cost], feed_dict={x: x_train, y: y_train})\n",
    "            epoch_loss+=c\n",
    "            print('Epoch', epoch, 'completed out of', hm_epochs,'loss: ',epoch_loss)\n",
    "        correct=tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        accuracy= tf.reduce_mean (tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', accuracy.eval({x:x_test, y:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10 loss:  2.4256336689\n",
      "Epoch 1 completed out of 10 loss:  1.96145665646\n",
      "Epoch 2 completed out of 10 loss:  1.96149492264\n",
      "Epoch 3 completed out of 10 loss:  1.96149492264\n",
      "Epoch 4 completed out of 10 loss:  1.96149492264\n",
      "Epoch 5 completed out of 10 loss:  1.96149492264\n",
      "Epoch 6 completed out of 10 loss:  1.96149492264\n",
      "Epoch 7 completed out of 10 loss:  1.96149492264\n",
      "Epoch 8 completed out of 10 loss:  1.96149492264\n",
      "Epoch 9 completed out of 10 loss:  1.96149492264\n",
      "Accuracy: 0.501209\n"
     ]
    }
   ],
   "source": [
    "train_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "The accuracy for the test data is - 50.12%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras - Tensorflow\n",
    "Importing models and layers from Keras Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable has 10 classes so, first we have to convert it into category and then get dummy variables for classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=np.array(train.drop('class', axis=1))\n",
    "y=pd.get_dummies(train['class'].astype('category'))\n",
    "y_train=np.array(y)\n",
    "\n",
    "x_test=np.array(test.drop('class', axis=1))\n",
    "y1=pd.get_dummies(test['class'].astype('category'))\n",
    "y_test=np.array(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am using 'RELU' activation function for the hidden layers and 'SOFTMAX' activation\n",
    "function for the output Layer. For the optimization i used Adam Optimizer. At each hidden layer i took 500 nodes and at output 10 nodes because we have 10 classes. Here i am using 50 epoch and batch size 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25010 samples, validate on 1000000 samples\n",
      "Epoch 1/50\n",
      "25010/25010 [==============================] - 61s - loss: 0.9946 - acc: 0.5138 - val_loss: 0.9526 - val_acc: 0.5422\n",
      "Epoch 2/50\n",
      "25010/25010 [==============================] - 62s - loss: 0.9558 - acc: 0.5456 - val_loss: 0.9568 - val_acc: 0.5327\n",
      "Epoch 3/50\n",
      "25010/25010 [==============================] - 63s - loss: 0.9453 - acc: 0.5542 - val_loss: 0.9362 - val_acc: 0.5586\n",
      "Epoch 4/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.9322 - acc: 0.5623 - val_loss: 0.9335 - val_acc: 0.5651\n",
      "Epoch 5/50\n",
      "25010/25010 [==============================] - 70s - loss: 0.9188 - acc: 0.5752 - val_loss: 0.9506 - val_acc: 0.5467\n",
      "Epoch 6/50\n",
      "25010/25010 [==============================] - 70s - loss: 0.9050 - acc: 0.5843 - val_loss: 0.9234 - val_acc: 0.5735\n",
      "Epoch 7/50\n",
      "25010/25010 [==============================] - 64s - loss: 0.8874 - acc: 0.5933 - val_loss: 0.8997 - val_acc: 0.5919\n",
      "Epoch 8/50\n",
      "25010/25010 [==============================] - 64s - loss: 0.8637 - acc: 0.6102 - val_loss: 0.8867 - val_acc: 0.5963\n",
      "Epoch 9/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.8374 - acc: 0.6250 - val_loss: 0.8620 - val_acc: 0.6130\n",
      "Epoch 10/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.8049 - acc: 0.6456 - val_loss: 0.8360 - val_acc: 0.6329\n",
      "Epoch 11/50\n",
      "25010/25010 [==============================] - 72s - loss: 0.7668 - acc: 0.6659 - val_loss: 0.7967 - val_acc: 0.6535\n",
      "Epoch 12/50\n",
      "25010/25010 [==============================] - 71s - loss: 0.7228 - acc: 0.6898 - val_loss: 0.7670 - val_acc: 0.6726\n",
      "Epoch 13/50\n",
      "25010/25010 [==============================] - 71s - loss: 0.6756 - acc: 0.7165 - val_loss: 0.7202 - val_acc: 0.7026\n",
      "Epoch 14/50\n",
      "25010/25010 [==============================] - 69s - loss: 0.6330 - acc: 0.7380 - val_loss: 0.6971 - val_acc: 0.7139\n",
      "Epoch 15/50\n",
      "25010/25010 [==============================] - 71s - loss: 0.5814 - acc: 0.7630 - val_loss: 0.6543 - val_acc: 0.7323\n",
      "Epoch 16/50\n",
      "25010/25010 [==============================] - 69s - loss: 0.5370 - acc: 0.7836 - val_loss: 0.6131 - val_acc: 0.7512\n",
      "Epoch 17/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.4969 - acc: 0.7989 - val_loss: 0.5586 - val_acc: 0.7816\n",
      "Epoch 18/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.4504 - acc: 0.8210 - val_loss: 0.5437 - val_acc: 0.7867\n",
      "Epoch 19/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.4002 - acc: 0.8440 - val_loss: 0.5456 - val_acc: 0.7886\n",
      "Epoch 20/50\n",
      "25010/25010 [==============================] - 65s - loss: 0.3702 - acc: 0.8547 - val_loss: 0.4844 - val_acc: 0.8192\n",
      "Epoch 21/50\n",
      "25010/25010 [==============================] - 69s - loss: 0.3209 - acc: 0.8766 - val_loss: 0.4270 - val_acc: 0.8360\n",
      "Epoch 22/50\n",
      "25010/25010 [==============================] - 66s - loss: 0.2946 - acc: 0.8869 - val_loss: 0.4122 - val_acc: 0.8431\n",
      "Epoch 23/50\n",
      "25010/25010 [==============================] - 69s - loss: 0.2465 - acc: 0.9059 - val_loss: 0.3624 - val_acc: 0.8666\n",
      "Epoch 24/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.2122 - acc: 0.9227 - val_loss: 0.3370 - val_acc: 0.8737\n",
      "Epoch 25/50\n",
      "25010/25010 [==============================] - 65s - loss: 0.1811 - acc: 0.9355 - val_loss: 0.3196 - val_acc: 0.8851\n",
      "Epoch 26/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.1519 - acc: 0.9480 - val_loss: 0.2234 - val_acc: 0.9225\n",
      "Epoch 27/50\n",
      "25010/25010 [==============================] - 64s - loss: 0.1152 - acc: 0.9643 - val_loss: 0.2384 - val_acc: 0.9158\n",
      "Epoch 28/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.1063 - acc: 0.9660 - val_loss: 0.2761 - val_acc: 0.9052\n",
      "Epoch 29/50\n",
      "25010/25010 [==============================] - 66s - loss: 0.1162 - acc: 0.9623 - val_loss: 0.2265 - val_acc: 0.9244\n",
      "Epoch 30/50\n",
      "25010/25010 [==============================] - 66s - loss: 0.0836 - acc: 0.9743 - val_loss: 0.1713 - val_acc: 0.9453\n",
      "Epoch 31/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.0559 - acc: 0.9852 - val_loss: 0.1560 - val_acc: 0.9516\n",
      "Epoch 32/50\n",
      "25010/25010 [==============================] - 65s - loss: 0.0531 - acc: 0.9846 - val_loss: 0.2002 - val_acc: 0.9366\n",
      "Epoch 33/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.1009 - acc: 0.9677 - val_loss: 0.1522 - val_acc: 0.9525\n",
      "Epoch 34/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0607 - acc: 0.9821 - val_loss: 0.2160 - val_acc: 0.9307\n",
      "Epoch 35/50\n",
      "25010/25010 [==============================] - 64s - loss: 0.0344 - acc: 0.9921 - val_loss: 0.1131 - val_acc: 0.9687\n",
      "Epoch 36/50\n",
      "25010/25010 [==============================] - 71s - loss: 0.0145 - acc: 0.9977 - val_loss: 0.1186 - val_acc: 0.9685\n",
      "Epoch 37/50\n",
      "25010/25010 [==============================] - 69s - loss: 0.0885 - acc: 0.9741 - val_loss: 0.2136 - val_acc: 0.9319\n",
      "Epoch 38/50\n",
      "25010/25010 [==============================] - 70s - loss: 0.0435 - acc: 0.9875 - val_loss: 0.1061 - val_acc: 0.9700\n",
      "Epoch 39/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.0212 - acc: 0.9954 - val_loss: 0.0986 - val_acc: 0.9725\n",
      "Epoch 40/50\n",
      "25010/25010 [==============================] - 64s - loss: 0.0292 - acc: 0.9918 - val_loss: 0.1208 - val_acc: 0.9657\n",
      "Epoch 41/50\n",
      "25010/25010 [==============================] - 65s - loss: 0.0636 - acc: 0.9807 - val_loss: 0.1231 - val_acc: 0.9637\n",
      "Epoch 42/50\n",
      "25010/25010 [==============================] - 66s - loss: 0.0379 - acc: 0.9888 - val_loss: 0.2332 - val_acc: 0.9308\n",
      "Epoch 43/50\n",
      "25010/25010 [==============================] - 65s - loss: 0.0439 - acc: 0.9864 - val_loss: 0.0843 - val_acc: 0.9784\n",
      "Epoch 44/50\n",
      "25010/25010 [==============================] - 64s - loss: 0.0104 - acc: 0.9978 - val_loss: 0.0831 - val_acc: 0.9784\n",
      "Epoch 45/50\n",
      "25010/25010 [==============================] - 66s - loss: 0.0230 - acc: 0.9932 - val_loss: 0.1490 - val_acc: 0.9564\n",
      "Epoch 46/50\n",
      "25010/25010 [==============================] - 70s - loss: 0.0897 - acc: 0.9733 - val_loss: 0.1122 - val_acc: 0.9672\n",
      "Epoch 47/50\n",
      "25010/25010 [==============================] - 69s - loss: 0.0144 - acc: 0.9965 - val_loss: 0.0618 - val_acc: 0.9837\n",
      "Epoch 48/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0574 - val_acc: 0.9861\n",
      "Epoch 49/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 0.9866\n",
      "Epoch 50/50\n",
      "25010/25010 [==============================] - 66s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0548 - val_acc: 0.9873\n"
     ]
    }
   ],
   "source": [
    "n_input_node= 25\n",
    "n_nodes_hl1=500\n",
    "n_nodes_hl2=500\n",
    "n_nodes_hl3=500\n",
    "n_output_node = 10\n",
    "\n",
    "epochs =50\n",
    "batch_size = 100\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=n_nodes_hl1, input_dim=n_input_node, activation='relu'),\n",
    " Dense(output_dim=n_nodes_hl2, input_dim=n_nodes_hl1, activation='relu'),\n",
    " Dense(output_dim=n_nodes_hl3, input_dim=n_nodes_hl2, activation='relu'),\n",
    "    \n",
    " Dense(output_dim=n_output_node, input_dim=n_nodes_hl3, activation='softmax')\n",
    " ])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model = model.fit(x_train, y_train, nb_epoch=epochs, batch_size=batch_size, \n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    " I am getting max accuracy of test data  - 98.73%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
